Copied all the code we did in class from rewatching recordings

I found it difficult and unreliable to code directly on the UNF servers
So I took the time and some stuff I learned at my current internship to set up
a github and Windows Subsystem for Linux running on VSC using Ubuntu as a terminal
and compiler.

I could not follow or understand 100% how the tokenizer workd
I found sscanf which can split the line into certain variables based on formatting
It has issues of its own as i discovered but tried mitigating
If i remember correctly that we discussed in class that isalpha might not be a great indicator 
I couldn't remember what the consensus was so i also imported <ctype.h> in headers.h
Added:
    char symbol[7];
    char opcode[32];
    char operand[32];
    int lineNum = 0;
    int address = 0;
    SymbolList table = {NULL};
and
Replaced:
        while (token - strtok(line, " ")) {
            printf("\tToken: %s\n", token);
            token = strtok(NULL, " \t\n");
        }
with if isalpha block
Added:
    memset(symbol, '\0', sizeof(symbol));
    memset(opcode, '\0', sizeof(opcode));
    memset(operand, '\0', sizeof(operand));
Because noticed that lines dont have the pertaining info it would display the previous

In headers.h
Added: 
int IsInSymbolTable(SymbolList table, char Test[7]);
void InsertSymbol(SymbolList table, char Name[7], int Addr, int LineNum);

I had an issue where InsertSymbols was not inserting anything.
The compiler was mentioning about incompatible typing.
Had to make the SymbolList table a pointer: *table in the function
and &table in p1.c

It then worked after than but worked like a stack so had to modify it so that would act like a queue instead.

After getting all the basic output corrected started working on the smaller details specfically targeting 
the test criteria.

A lot of small things came up like how it was not picking up duplicates and it turns out that the temp did not copy the table.